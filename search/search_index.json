{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to my documentation!</p> <p>This is a place where I collate time-saving answers to those infrequent, yet annoying, tasks.</p> <p>Check out the sections with the tabs above! Once you have a tab, use the navigation menu to browse different topics!</p>"},{"location":"dual-boot/ubuntu-windows-setup/","title":"Custom Linux (Ubuntu) Install - Method for Setting Up Dual Boot","text":"<p>Before proceeding make note of the disk partitioning scheme on the boot drive (MBR or GPT) and the boot mechanism (BIOS/Legacy or EFI). On linux, you can check for the presence of <code>/sys/firmware.efi</code>; on windows, this can be found with <code>msinfo32</code>. When creating the boot media, most support both EFI and BIOS/Legacy if the boot media is installed with either MBR or GPT. However, when actually booting to that USB device, ensure that the correct boot mechanism (BIOS/Legacy or EFI) is being used. If a warning comes up on the last stage of the install, you probably have not matched the boot mechanism with the existing boot mechanism and will get a failed install.</p> <p>Usually best to install Windows first over the whole disk for a dual boot setup.</p> <ol> <li>Continue wizard until \"Installation type\"</li> <li>Select \"Something else\"</li> <li>(For dual boot) Shrink Windows partition to make free space. Recovery partition can be left untouched.</li> <li>Create the following partitions<ol> <li>Swap partition<ul> <li>Size: &gt;= RAM (for hibernation)</li> <li>Type: Primary (can be logical if \"unstable\" issue occurs)</li> <li>Location: Beginning of space</li> <li>Use as: swap area</li> </ul> </li> <li>Root filesystem - used for kernel, boot files, system files, (most) installed programs, libraries, etc.<ul> <li>Size: &gt;20GB, I recommend 50GB</li> <li>Type: Logical</li> <li>Location: Beginning of space</li> <li>Use as: ext4 fs</li> <li>Mount point: /</li> </ul> </li> <li>Home directory - used for user files. (For dual boot systems I recommend having a common data partition so this becomes less needed)<ul> <li>Size: Up to you. Recommended &gt;10GB</li> <li>Type: Logical</li> <li>Location: Beginning of space</li> <li>Use as: ext4 fs</li> <li>Mount point: /home</li> </ul> </li> </ol> </li> </ol>"},{"location":"dual-boot/windows-without-grub-menu/","title":"Windows Booting Without GRUB Boot Menu even appearing","text":"<p>This can sometimes happen after a Windows update; the bootloader default has been set to Windows rather than <code>GRUB</code>.</p> <p>To fix: set bootloader back to <code>GRUB</code> 1. Open <code>cmd</code> (Administrator) 2. <code>bcdedit /set {bootmgr} path \\EFI\\ubuntu\\grubx64.efi</code></p>"},{"location":"git/alias/","title":"Git Alias","text":"<p>You can create custom git commands with git alias</p> <pre><code>git config [--global] alias.co \"checkout\"\n</code></pre>"},{"location":"git/checkout-deprecation/","title":"The splitting/deprecation of git checkout","text":"<p>The <code>git checkout</code> command has two distinct uses. One is to switch and/or create branches and the other is to restore files to a previous index. These two functions have been separated out to avoid confusion.</p>"},{"location":"git/checkout-deprecation/#switch","title":"Switch","text":"<p>To switch branches, you should now use the following:</p> <pre><code>git switch &lt;branch&gt;\n</code></pre> <p>adding <code>-c</code> to create a new branch.</p>"},{"location":"git/checkout-deprecation/#restore","title":"Restore","text":"<p>To restore files from a previous index, you should now use the following:</p> <pre><code>git restore -s &lt;ref&gt; &lt;path&gt;\n</code></pre> <p>This allows a new feature: restoring with patches using the <code>-p</code> command, similar to it's usage in <code>git add</code>.</p>"},{"location":"git/diff/","title":"Diff","text":"<p><code>git diff</code> is a very powerful feature.</p> <p>One notable use of git diff is that it provides more options than regular <code>diff</code>. For example, if there is one small change within one long line, regular <code>diff</code> cannot highlight this for you. <code>git diff</code>, on the other hand, can with the <code>--word-diff</code> flag. Furthermore, <code>git diff</code> can be used outside a git repository using the <code>--no-index</code> flag. This allows is to function as a powerful diff replacement.</p> <p><code>git diff</code> can also be used in patching.</p>"},{"location":"git/dotfile/","title":"Git Dotfile","text":"<p>Global git config is stored in <code>$HOME/.gitconfig</code>.</p>"},{"location":"git/logdog/","title":"Pretty Print Git History Graph","text":"<p>This can be achieved with the following command:</p> <pre><code>git log --decorate --oneline --graph\n</code></pre> <p>This is sometimes referred to as \"git logdog\" and is therefore often aliased as such.</p>"},{"location":"git/patch/","title":"Patch","text":""},{"location":"git/patch/#interactive-patch-staging","title":"Interactive Patch Staging","text":"<ul> <li>If you have modified a file in multiple places but want to only commit some of your changes git add has a patch option that allows you to interactively choose which parts of the file to stage.</li> </ul> <pre><code>git add [&lt;files&gt;] -p\n</code></pre>"},{"location":"git/patch/#creating-and-applying-patches","title":"Creating and Applying Patches","text":"<ul> <li>Similar to patch git can be used to make patches</li> <li> <p>The benefit when working in a git repository is that filenames/paths are registered in git history and do not need to be specified</p> </li> <li> <p>To create a diff</p> </li> </ul> <pre><code>git diff [&lt;files&gt;] &gt; mypatch.patch\n</code></pre> <ul> <li>To apply a diff</li> </ul> <pre><code>git apply mypatch.patch\n</code></pre> <ul> <li>To revert a diff</li> </ul> <pre><code>git apply -R mypatch.patch\n</code></pre>"},{"location":"git/pre-commit/","title":"Pre-commit","text":"<p>The pre-commit script found in the local git repository (<code>.git/hooks/pre-commit)</code> can be any executable and will run before a <code>git commit</code>. A useful use case is to check the formatting of code. N.B it is not best practice to modify files in the pre-commit as tempting as it might be, since you may not always want the files to change and this can be frustrating. It is better practice to abort the commit (non-zero return from <code>pre-commit</code>) and warn why. If, after being warned, you want to commit anyway, pass <code>--no-verify</code> to <code>git commit</code>.</p>"},{"location":"git/pre-commit/#example","title":"Example","text":"<p>An example <code>pre-commit</code> script might be the following:</p> <pre><code>#!/bin/bash\n\n# Exit on any fail and prevent commit\nset -e\n\nfor file in $(git diff --cached --name-only --diff-filter=d | grep \"\\.py$\")\ndo\n  black --check $file\ndone\n</code></pre>"},{"location":"git/rebase/","title":"Rebase","text":"<p>Rebasing is a method of overwriting history by moving commits fromone place to another.</p> <p>Typical usage may look like</p> <pre><code>git rebase main\n</code></pre> <p>which will move the commits from the current branch onto the main branch.</p>"},{"location":"git/rebase/#onto","title":"Onto","text":"<p>A typical scenario is creating a branch from an existing non-default branch to continue working (whilst the base branch is in review). Once the base branch has been merged into the default branch, we want to move the new commits to a new branch off the default branch. This is achieved using the following.</p> <pre><code>git rebase --onto &lt;default_branch&gt; &lt;beginning_of_your_work_exclusive&gt; &lt;end_of_your_work_inclusive&gt;\n</code></pre>"},{"location":"git/rebase/#interactive","title":"Interactive","text":"<p>For anything more complicated, I recommend using </p> <pre><code>git rebase &lt;new_base&gt; -i\n</code></pre> <p>Which can allow you to squash commits etc.</p>"},{"location":"git/rebase/#fixups","title":"Fixups","text":"<p>To fix a previous commit and automatically rebase, you can do the following:</p> <pre><code>git commit --fixup &lt;ref&gt;\nGIT_SEQUENCE_EDITOR=: git rebase -i --autosquash &lt;ref&gt;~1\n</code></pre>"},{"location":"git/rebase/#rerere","title":"rerere","text":"<p>To Reuse a previous Recorded conflict Resolution automatically, enable <code>git rerere</code>.</p> <pre><code>git config --global rerere.enabled true\n</code></pre> <p>If you do need to resolve a conflict differently, you can use the following after the fact.</p> <pre><code>git checkout --conflict=merge &lt;path&gt;\n</code></pre>"},{"location":"git/root/","title":"Report Root Directory of Current Git Repo","text":"<p>This can be achieved with the following command:</p> <pre><code>git rev-parse --show-toplevel\n</code></pre>"},{"location":"git/submodules/","title":"Submodules","text":"<p>Submodules are a powerful git feature that allows other git repositories to be used with a super-repository whilst maintaining individual version control.</p> <p>These commands will help to quickly start using git submodules</p> <ul> <li><code>git submodule add &lt;remote&gt;</code>: add a new git submodule</li> <li><code>git submodule update</code>: checkout commited index of submodules<ul> <li><code>--init</code>: also initialise git submodules. This is required after a new <code>git clone</code></li> <li><code>--remote</code>: checkout the most recent commit for the submodules rather than the one in the index</li> </ul> </li> </ul> <p>Simply <code>cd</code> into the respective submodule directory to access git commands respective to that submodule.</p>"},{"location":"linux/automatic-mount-on-boot/","title":"Automatic mount on boot","text":""},{"location":"linux/automatic-mount-on-boot/#to-automatically-mount-drives-on-boot","title":"To Automatically Mount Drives on Boot","text":"<p>Use <code>gnome-disks</code> 1. Select partition -&gt; Edit Mount Options 1. Turn off \"user session defaults\" 1. Select \"Mount at system startup\" 1. Fill in other fields as desired (including mount point) 1. reboot</p>"},{"location":"linux/background-processes/","title":"Handling Background Processes","text":""},{"location":"linux/background-processes/#quick-reference","title":"Quick Reference","text":"<ul> <li><code>Ctrl + Z</code>: suspend job in background</li> <li><code>jobs</code>: list jobs</li> <li><code>bg</code>: resume a job in the background</li> <li><code>fg</code>: bring a job to the foreground</li> <li><code>wait</code>: wait for background jobs to finish</li> <li><code>foo &amp;</code>: only runs <code>foo</code> in the background; stdin and stdout are still connected</li> <li><code>foo &gt;/dev/null 2&gt;&amp;1 &amp;</code>: runs foo in the background and pipe all output to <code>/dev/null</code>. Some shells allow this syntax: <code>foo &amp;&gt;/dev/null &amp;</code>. stdin is still connected</li> <li><code>nohup foo</code>: Pipes stdout and stderr to <code>nohup.out</code>. stdin reads will result in errors or EOF. A foreground <code>nohup</code>'d job makes no real sense, so normally use <code>nohup foo &amp;</code></li> <li><code>disown</code>: remove ownership of a job from the current shell. This means the current shell can be closed without killing the job. <code>nohup</code> does not do this by itself, so using <code>disown</code> after <code>nohup</code> is a good idea</li> <li><code>stty tostop</code> or <code>stty -tostop</code>: Send (or do not send) <code>SIGTTOU</code> for background jobs if they try to write output. This causes background jobs to stop (or not) if they attempt terminal output.</li> </ul>"},{"location":"linux/background-processes/#in-scripts","title":"In scripts","text":"<p>See this code snippet on how to handle background processes within a script!</p> <pre><code>#!/usr/bin/env bash\n\necho \"Starting a\"\n./a.sh | sed 's/^/A: /'&amp;\n\necho \"Starting b\"\n./b.sh | sed 's/^/B: /'&amp;\n\n# Forward signals to child processes\ntrap 'trap \"\" SIGTERM; kill 0; wait' SIGINT SIGTERM\n# Wait for child processes to finish\nwait\n</code></pre> <p>The <code>trap</code> command allows you to catch signals and execute code when they occur. In this case we remove the trap and execute a <code>kill</code> and <code>wait</code> on any SIGINT or SIGTERM.</p>"},{"location":"linux/compression/","title":"Compression","text":""},{"location":"linux/compression/#gzip","title":"<code>gzip</code>","text":"<p>The <code>gzip</code> command can be used to compress single files. Add the <code>-#</code> replacing <code>#</code> with a number 1-9, for setting the compression level.</p>"},{"location":"linux/compression/#pigz","title":"<code>pigz</code>","text":"<p>By default, <code>gzip</code> does not use all cores. This can be ammended by using the <code>pigz</code> command instead. <code>pigz</code> is fully compatible with <code>gzip</code></p>"},{"location":"linux/compression/#tar","title":"<code>tar</code>","text":"<p><code>gzip</code> can only compress a single file. <code>tar</code> (or <code>zip</code> - difference being inter-file compression in <code>tar</code>) creates a single archive file from multiple. Combining <code>tar and gzip</code> is the standard way of making compressed archives.</p> <ul> <li><code>-c</code> : Creates archive (recursive by default)</li> <li><code>-x</code> : Extracts the archive</li> <li><code>-f</code> : Creates archive with given filename (use <code>-</code> for stdout)</li> <li><code>-v</code> : Displays verbose information</li> <li><code>-z</code> : Compresses the tar file using gzip</li> </ul>"},{"location":"linux/compression/#examples","title":"Examples","text":""},{"location":"linux/compression/#create-a-compressed-archive","title":"Create a compressed archive","text":"<pre><code>tar cfzv archive.tar file1 file2 file3\n</code></pre>"},{"location":"linux/compression/#decompress-an-archive","title":"Decompress an archive","text":"<pre><code>tar xfv archive.tar\n</code></pre>"},{"location":"linux/compression/#create-a-compressed-archive-using-all-cpu-cores-and-the-best-compression-level","title":"Create a compressed archive using all CPU cores and the best compression level","text":"<pre><code>tar cf - paths-to-archive | pigz -9 &gt; archive.tar.gz\n</code></pre>"},{"location":"linux/ffmpeg/","title":"ffmpeg","text":"<p>ffmpeg is a fantastic tool that allows complete conversion of video formats</p>"},{"location":"linux/ffmpeg/#basic-syntax","title":"Basic syntax","text":"<pre><code>ffmpeg -i input.avi output.mp4`\n</code></pre> <pre><code>ffmpeg -i img%03d.png out.mp4\n</code></pre>"},{"location":"linux/ffmpeg/#gotchas","title":"Gotchas","text":"<ul> <li>Not all h264 formats are available on multiple platforms. The most platform-agnostic format is <code>yuv420p</code> (nothing to do with 420 pixels)     <code>bash     ffmpeg -i input.mp4 -vf format=yuv420p output.mp4</code> </li> </ul>"},{"location":"linux/gpg/","title":"Encryption","text":"<p>Encryption can be achieved either using <code>gpg</code> and/or <code>openssl</code>.</p>"},{"location":"linux/gpg/#symmetric-encryption","title":"Symmetric Encryption","text":"<p>A simple symmetric encryption can be achieved with the following:</p> <pre><code>gpg -c &lt;file&gt;\n</code></pre> <p>which will prompt for a passphrase and produce an encrypted file with an appended <code>.gpg</code> suffix.</p> <p>To decrypt the encrypted file use the following:</p> <pre><code>gpg &lt;encrypted_file&gt;\n</code></pre>"},{"location":"linux/gpg/#encryption-algorithm","title":"Encryption Algorithm","text":"<p><code>gpg</code> allows a number of algorithms. To view these algorithms run:</p> <pre><code>gpg --version\n</code></pre> <p>For symmetric encryption, look for algorithms listed under <code>Cypher:</code>.</p> <p>Using one of these algorithms can be achieved as follows.</p> <pre><code>gpg --cipher-algo &lt;ALGO&gt; &lt;file&gt;\n</code></pre> <p>No change is required to the decrypt command.</p>"},{"location":"linux/gpg/#asymmetric-encryption","title":"Asymmetric Encryption","text":"<p>You can see a list of keys with <code>gpg --list-keys</code>. <code>--list-secret-keys</code> and <code>--list-public-keys</code> are also available.</p> <ol> <li> <p>Generate a key pair</p> <p><code>bash gpg --gen-key</code></p> </li> <li> <p>Export your public key</p> <p><code>bash gpg --export --armor &lt;name&gt; &gt; &lt;name&gt;.pub</code></p> </li> <li> <p>(Optional) Make a backup of your private key. Only ever store this backup in offline media.     <code>bash     gpg --export-secret-keys --armor &lt;name&gt; &gt; &lt;name&gt;.priv</code></p> </li> <li> <p>Import the other's public key</p> <p><code>bash gpg --import key.pub</code></p> </li> <li> <p>(Optional) Trust the key</p> <p><code>bash gpg --edit-key &lt;name&gt;</code> Enter <code>trust</code> then the level you wish to trust it to</p> </li> <li> <p>Encrypt a file</p> <p><code>bash gpg --encrypt --recipient &lt;recipient&gt; &lt;file&gt;</code></p> </li> <li> <p>Decrypt a received file</p> <p><code>bash gpg --decrypt &lt;file&gt;.gpg --output &lt;file&gt;</code></p> </li> </ol>"},{"location":"linux/grep/","title":"grep","text":"<p><code>grep</code> is a well-known, useful command line utility to filter stdin. Here are some lesser-known features.</p>"},{"location":"linux/grep/#regular-expressions","title":"Regular expressions","text":"<p>Invoking <code>grep</code> with the <code>-E</code> flag allows you to use extended regular expressions.</p>"},{"location":"linux/grep/#matching-patterns-that-come-from-a-file","title":"Matching patterns that come from a file","text":"<p>You might be in a use case where your patterns are defined in a file and you want to use this to grep your input. This template can be (modified and) used to achieve this.</p> <pre><code>grep $(sed \"s/^/-e /;s/$/ /\" patterns.txt | tr -d \"\\n\")\n</code></pre>"},{"location":"linux/installing-app-images/","title":"Installing *.AppImage applications","text":"<ul> <li>Make use of https://github.com/TheAssassin/AppImageLauncher</li> <li>If you want to also be able to run a command from terminal, symlink the installed application (set up in AppImageLauncher) to <code>/usr/local/bin</code></li> </ul>"},{"location":"linux/managing-installs/","title":"Managing Installed Programs","text":"<ol> <li>Find manually installed programs to find those you no longer need     <code>bash     sudo apt-mark showmanual     snap list # for any programs installed by snap</code></li> <li>Clean list of <code>ppa</code>s after uninstalling<ul> <li><code>ppa</code>s are listed in the <code>sources.list</code> file and as individual files in the <code>sources.list.d/</code> subfolder in <code>etc/apt</code></li> </ul> </li> </ol>"},{"location":"linux/mounting-drive-partitions/","title":"Mounting Drives/Partitions","text":"<ul> <li>Use <code>gparted</code> or <code>gnome-disks</code> to find (with GUI) partition name. Or use <code>fdisk -l</code> to do this via command line (harder to understand). N.B: devices look like <code>/dev/sdx</code> and partitions look like <code>/dev/sdxY</code>. e.g. <code>/dev/sda</code> and <code>/dev/sda1</code> respectively.</li> </ul> <p><code>bash   mount &lt;parition_name&gt; &lt;mount_point&gt; -o uid=$UID -o gid=$GID   # ... When finished, don't forget to   umount &lt;mount_point&gt;</code></p> <ul> <li>To mount part of a hard drive into the local directory (e.g. so that docker can use it without symlinks), add the following to <code>/etc/fstab</code></li> </ul> <p><code># Bind /hdd/server to /home/server/hdd   /hdd/server /home/server/hdd none defaults,bind 0 0</code></p> <p>Similar to this is what is happening automatically when using <code>gnome-disks</code></p>"},{"location":"linux/mounts-in-dock/","title":"To Turn On/Off Mounts from Appearing in the Dock","text":"<pre><code>gsettings set org.gnome.shell.extensions.dash-to-dock show-mounts &lt;true|false&gt;\n</code></pre>"},{"location":"linux/named-pipes/","title":"Named Pipes","text":"<ul> <li>A named pipe can be used to communicate between processes.</li> <li> <p>A named pipe can be created with the following:</p> <p><code>sh mkfifo</code></p> </li> <li> <p>It is important to note that writing to a named pipe will fail or at best hang unless something is also reading from the pipe</p> </li> <li> <p>Named pipes can be used to create circular communications between applications too. This can be used, for example, to allow a scripted agent to communicate with a prompt-like process.</p> <p><code>sh mkfifo fifo cat fifo | tee fifo</code></p> <p>In this example, the first process (<code>cat</code>) is reading from <code>fifo</code> and outputting to stdin. The second process (<code>tee</code>) is reading stdin and writing it to tty as well as back to <code>fifo</code>, closing the loop * Note that stdin/stdout may be buffered and interfere with this loop. To fix this, you can use <code>stdbuf -i0 -o0</code> as a prefix to the second process.</p> </li> </ul>"},{"location":"linux/networking/","title":"Networking","text":""},{"location":"linux/networking/#ip-rules","title":"IP rules","text":"<p>The <code>iptables</code> command can be used to create IP rules such as dropping, rejecting, masquerading or forwarding packets that meet certain criteria. This is how wireguard is configured. It is important to note, however, that <code>iptables</code> rules only persist whilst the host is up and are lost at reboot.</p> <p>A good alternative is the uncomplicated firewall of <code>ufw</code>, which uses <code>iptables</code> under the hood, but provides a more user-friendly interface and manages persistence of <code>iptables</code> rules. A very important notice is that docker creates it's own <code>iptables</code> rules for it's own networking capabilities. This happens in the layer before <code>ufw</code> and therefore <code>ufw</code> rules configured for endpoints that docker controls will not take affect!</p> <p><code>iptables</code> can be used for network address translation (or NAT). Whilst this works perfectly for TCP connections that have state, UDP packets are stateless, without additional software (such as a STUN server), UDP packets cannot successfully be routes through NATs since they require full bidirectional communication before they are considered <code>ESTABLISHED</code> (at which point a NAT entry would suffice). This can be confirmed using <code>conntrack</code> and wireshark.</p>"},{"location":"linux/networking/#choice-of-vpn-software","title":"Choice of VPN software","text":"<p>There is a long-fought argument between Wireguard and OpenVPN. I have personally had success with both, however since Wireguard makes use of a new network kernel interface (called <code>wg0</code>) NAT is as-good-as mandatory. Due to the issues above with UDP and NAT, I prefer to use OpenVPN since it can be configured (without NAT) much more easily.</p>"},{"location":"linux/parallel/","title":"GNU Parallel","text":"<p>To execute arbitrary commands in parallel (multi-process), making use of additional CPU cores, across input data, GNU <code>parallel</code> can be used.</p> <p>A basic example is as follows:</p> <pre><code>find . -name '*.html' | parallel gzip --best\n</code></pre> <p>and more examples can be found here.</p> <p>For simple use cases, particularly where you do not need to collate stdout, <code>xargs</code> with the <code>-P</code> option may also be used.</p>"},{"location":"linux/patch/","title":"Patch","text":"<p>The <code>patch</code> command can usefully apply patches that are created with the <code>diff</code> tool.</p> <p>For example: Generate a patch file</p> <pre><code>diff foo.txt bar.txt &gt; foo2bar.patch\n</code></pre> <p>Apply the patch file</p> <pre><code>patch foo.txt foo2bar.patch\n</code></pre> <p>Reverse the patch</p> <pre><code>patch -R foot.txt foo2bar.patch\n</code></pre>"},{"location":"linux/prevent-sleep/","title":"Prevent/Allow Ubuntu Sleeping","text":"<p>e.g. For an Ubuntu Server</p> <pre><code>sudo systemctl &lt;mask|unmask&gt; sleep.target suspend.target hibernate.target hybrid-sleep.target\n</code></pre> <p><code>mask</code> to prevent sleeping, <code>unmask</code> to (re)allow sleeping</p>"},{"location":"linux/ram-disk/","title":"RAMDisk","text":"<pre><code>mount -t tmpfs -o rw,size=&lt;size&gt; &lt;name&gt; &lt;mount_point&gt;\n# ... When finished, don't forget to\numount &lt;local_mount_point&gt;\n</code></pre>"},{"location":"linux/recover-bad-kernel/","title":"Recovering from a bad kernel installation","text":"<p>Every now and then you may come across a bad kernel installation. The symptoms for this are usually hardware issues: graphics, keyboard/mouse/touchpad and network and the most common.</p> <p>To fix this, use GRUB to see \"Additional options\" and select a version with a previous kernel.</p> <p>This should launch with everything working.</p> <p>The most likely fix here is to <code>apt update</code> and <code>apt upgrade</code> as the bug will probably be fixed. In rare cases where this is not the case, uninstalling the old linux kernel will prevent needing to use additional options every time, but this will only last until you next have an update (which hopefully fixes it anyway!).</p>"},{"location":"linux/recover-bad-kernel/#useful-commands","title":"Useful commands","text":"<p>To check current linux kernel version</p> <pre><code>uname -r\n</code></pre> <p>To see installed kernels</p> <pre><code>dpkg --list | grep linux-image\n</code></pre>"},{"location":"linux/remote-file-access/","title":"Remote File Access","text":""},{"location":"linux/remote-file-access/#sftp","title":"<code>sftp</code>","text":"<ul> <li>Good for simple single file transfers</li> <li><code>-a</code> flag is really useful to continue transfer if it gets interrupted</li> </ul>"},{"location":"linux/remote-file-access/#sshfs","title":"<code>sshfs</code>","text":"<ul> <li>Mounts the remote file system</li> <li>Method:     <code>bash     mkdir &lt;local_mount_point&gt; # (usually /tmp/remote is a good choice)     sshfs &lt;user&gt;@&lt;remote&gt;:&lt;remote_mount_point&gt; &lt;local_mount_point&gt;     # ... When finished, don't forget to     umount &lt;local_mount_point&gt;</code></li> </ul>"},{"location":"linux/screen-recording/","title":"Screen Recording","text":"<p>I like to use Peek for screen recording.</p>"},{"location":"linux/ssh-display/","title":"Graphical Applications Over SSH","text":"<ul> <li>Pass the <code>-X</code> or <code>-Y</code> flag</li> <li>Need <code>$DISPLAY</code> environment variable. If using <code>sudo</code>, use <code>sudo -E</code>.</li> </ul>"},{"location":"linux/ssh-vpn/","title":"SSH as a VPN","text":"<p><code>ssh</code> can actually be used to tunnel network traffic also!</p> <pre><code>ssh -N -L &lt;local_port&gt;:&lt;remote&gt;:&lt;remote_port&gt; &lt;user&gt;@&lt;remote&gt;\n</code></pre> <p>e.g.</p> <pre><code>ssh -N -L 12345:example.com:443 james@abc.com\n</code></pre> <p>Will set up a tunnel such that <code>example.com:443</code> (443 is <code>https</code>) can be accessed at <code>localhost:12345</code> tunnelling traffic through <code>james@abc.com</code></p>"},{"location":"linux/ssl/","title":"SSL Certificates","text":"<p>To generate an SSL certificate and private key pair, use the following command:</p> <pre><code>openssl req -x509 -newkey rsa:4096 -keyout privatekey.key -out public-certificate.crt -sha256 -days 365\n</code></pre> <ul> <li>Add the <code>-nodes</code> flag to disable DES passphrase encryption</li> <li>Add the <code>-addext \"subjectAltName = DNS:foobar.com,IP:111.222.111.222\"</code> to specify a subjectAltName</li> <li><code>-days</code> specifies the time until expiry</li> </ul>"},{"location":"linux/sudo/","title":"<code>sudo</code>","text":"<p>There are two commands that can be used to run commands as other users: <code>sudo</code> and <code>su</code>. The primary difference between these two is that <code>sudo</code> is highly configurable on which user and which commands whereas <code>su</code> provides blanket access. Additionally, <code>su</code> requires the password of the user that is being switched to whereas <code>sudo</code> (normally) requires the password of the user running the command, so is more friendly. If using these commands for <code>root</code> access, it is alwalys recommended to use <code>sudo</code> over <code>su</code>. The only time it is recommended to instead use <code>su</code> is to login (with a shell session rather than one command) to the account of another non-root user for whom you have access/know the password.</p>"},{"location":"linux/sudo/#sudoers-config-file","title":"sudoers Config file","text":"<p><code>sudo</code> is very configurable. The config file is <code>/etc/sudoers</code>, however it should only ever be edited with <code>sudo visudo</code> to perform syntax checks before saving. Additionally, the majority of configurations should not change the default <code>/etc/sudoers</code> file, but rather add additional permitted behaviour by adding new files to <code>/etc/sudoers.d</code>. Write these files with <code>sudoedit</code>, but check them with <code>sudo visudo --check</code>.</p> <p>The primary syntax is the following:</p> <p><code>User OnHost = (Runas-User:Group) &lt;space&gt; Commands</code></p> <p>To put it very simple, it is \u201cwho where = (as_whom) what\u201d</p> <p>By default, if a command is given only as a binary, any arguemnts can be provided. Specific arguments can be specified to restrict this behaviour.</p> <p>There are other, use-case-specific, behaviours that can be used, but a common one is to not require a password when running certain <code>sudo</code> commands. This is achieved with the <code>NOPASSWD:</code> directive that is prepended before the command.</p>"},{"location":"linux/terminal-clipboard/","title":"Use of the (Desktop) Clipboard in the Command Line","text":""},{"location":"linux/terminal-clipboard/#clipcopy-and-clippaste","title":"<code>clipcopy</code> and <code>clippaste</code>","text":"<ul> <li>When using a oh-my-zsh, the commands <code>clipcopy</code> and <code>clippaste</code> can be used to access the clipboard. These commands are platform-agnostic </li> </ul>"},{"location":"linux/terminal-clipboard/#xclip","title":"<code>xclip</code>","text":"<ul> <li><code>-o</code>: paste to <code>stdout</code></li> <li>Use <code>-sel clip</code> option to use the main clipboard. Defaults to middle-mouse-click temporary clipboard otherwise.</li> <li>Very useful when combined with pipes e.g. <code>echo \"test\" | xclip -sel clip</code></li> </ul>"},{"location":"linux/terminal-clipboard/#clipexe-for-wsl","title":"<code>clip.exe</code> for WSL","text":"<ul> <li>Copy into the Windows clipboard from WSL can be done by piping into <code>clip.exe</code></li> </ul>"},{"location":"linux/updating-ubuntu/","title":"Updating Ubuntu","text":""},{"location":"linux/updating-ubuntu/#do-a-fresh-install","title":"Do a fresh install!","text":"<p>If your ~/home is on a separate partition, that does not need to be reformated and can be kept!</p> <p>Although why not take the opportunity to start fresh!</p>"},{"location":"linux/updating-ubuntu/#gui-recommended","title":"GUI (recommended)","text":"<p>Sotware Updater</p>"},{"location":"linux/updating-ubuntu/#terminal","title":"Terminal","text":"<pre><code>sudo apt update\nsudo apt upgrade\nsudo do-release-upgrade # -c to check for upgrades\n</code></pre>"},{"location":"linux/updating-ubuntu/#after-the-updates","title":"After the updates","text":"<ul> <li>Some <code>ppa</code>s and software might have been removed</li> </ul>"},{"location":"linux/updating-ubuntu/#gui-recommended_1","title":"GUI (recommended)","text":"<p>Can be launched with <code>software-properties-gtk</code> (e.g. with ssh -X or -Y) * Remove anything from \"other software\" and \"authentication\" that has been disabled by the upgrade and make a note of which.</p>"},{"location":"linux/updating-ubuntu/#terminal_1","title":"Terminal","text":"<ul> <li>Manipulate <code>sources.list</code> to remove any software that was disabled by the upgrade and make a note of which.</li> </ul> <ul> <li><code>apt update</code> should now run without any errors or warnings</li> <li>Reinstall those that were removed</li> </ul>"},{"location":"linux/version-management/","title":"Managing Versions of Programs on the Path","text":"<p>This is particularly relevant for Java (especially when wanting to work with Oracle Java), so these instructions will be tailored to that.</p> <ol> <li>Install version files (for java to <code>/usr/lib/jvm/jdkx.x.x_xxx</code>)</li> <li>Register with <code>update-alternatives</code> <code>bash     sudo update-alternatives --install \"/usr/bin/java\" \"java\" \"/usr/lib/jvm/jdkx.x.x_xxx/bin/java\" 1</code>     Installation to, command name, program file, priority for auto-selection (not relevant as we will use manual selection)</li> <li>Select which version to use     <code>bash     sudo update-alternatives --config java</code>     Then type the chosen installation number</li> </ol> <p>N.B for java, it is best to do this process for <code>java</code> and <code>javac</code></p>"},{"location":"linux/xargs/","title":"xargs","text":"<p><code>xargs</code> is a command line utility that formats stdin correctly for another program's arguments and invokes that program</p> <p>For example, by default the command <code>ls</code> outputs over a number of lines, but <code>ls | xargs</code> will push these onto one line (space-separated). This is very useful for substituting a command's results in another command. e.g. <code>ls | xargs rm</code>. N.B: this is a contrived example where <code>rm -r *</code> would be easier.</p> <p><code>xargs</code> is therefore very useful for scripting, but it also becomes essential if you would otherwise have a massive number of program arguments. For example if you were deleting thousands of files (by name (contrived example)) and were to put them all onto the command line with <code>$()</code>, some would be cut short since there is a maximum argument limit. <code>xargs</code> obeys this and will split the call into multiple calls if necessary to accommodate this. This can be manually achieved with the <code>-n &lt;n&gt;</code> argument which allows only <code>n</code> arguments per call. This also opens up much more scripting potential.</p>"},{"location":"linux/zsh-ordering/","title":"ZSH script ordering","text":"<p>The following scripts run in order for the setup of a zsh shell.</p> <ol> <li><code>.zshenv</code> is always sourced</li> <li><code>.zprofile</code> runs for login shells</li> <li><code>.zshrc</code> only runs in interactive shells. Only include setup for interactive shells here</li> <li> <p><code>.zlogin</code> runs for login shells. Much like <code>.zprofile</code>, but the shell can be considered fully set up</p> </li> <li> <p><code>.zlogout</code> runs to teardown anything set up in <code>.zlogin</code></p> </li> </ol>"},{"location":"linux/zsh-ordering/#login-shells","title":"Login shells","text":"<p>A login shell is either that initially logged into or accessed with <code>ssh</code>. A notable exception therefore are terminal sessions launched through the terminal apps in any UI session. For my usage, I find this to be inconvenient, so I will look for and enable a setting to launch these terminal sessions as login shells.</p>"},{"location":"linux/tmux/shared-session/","title":"Shared tmux Sessions","text":""},{"location":"linux/tmux/shared-session/#background","title":"Background","text":"<ul> <li>tmux will create (directories of) sockets within <code>TMUX_TMPDIR</code> or <code>/tmp</code> if unset.</li> <li>The default socket name is <code>default</code> within this folder<ul> <li>This can be changed per call with the <code>-L</code> flag</li> </ul> </li> <li>The socket path (e.g. <code>/tmp/tmux-1000/default</code>) can be changed with the <code>-S</code> flag</li> </ul>"},{"location":"linux/tmux/shared-session/#sharing","title":"Sharing","text":"<ul> <li>To share a session, simply allow other users (via linux user groups) access to the socket</li> <li>In version (<code>tmux -V</code>) 3.3 and later an additional step is required.<ul> <li>Use <code>tmux server-access -a &lt;user&gt;</code> to add a user (specificying <code>-r</code> or <code>-w</code> for read or write access)</li> </ul> </li> </ul>"},{"location":"linux/tmux/start-in-detached/","title":"Starting Services in Detached Sessions","text":"<pre><code>tmux new -d [-s &lt;session_name&gt;] \"&lt;starting_command&gt;\"\n</code></pre>"},{"location":"programming/gdb/","title":"GDB Debugging","text":"<ul> <li> <p><code>tui enable</code> enables the text-user-interface mode where you can see in with a split-window the current code location</p> <ul> <li><code>focus cmd</code> to make arrows keys work normally in tui mode</li> <li>ctrl+l if tui mode messes up</li> </ul> </li> <li> <p>tab autocomplete to find options</p> </li> <li> <p>breakpoints</p> </li> <li> <p><code>tbreak</code>: temporary break</p> </li> <li> <p><code>rbreak</code>: match regular expression to break point locations and add for all of them</p> </li> <li> <p><code>crtl+x+2</code>: second window; cycle through</p> </li> <li> <p><code>ignore &lt;breakpoint number&gt; &lt;occurunces&gt;</code> to skip over a breakpoint a certain number of times -&gt; very useful if determinsitic program fails after a certain number of times</p> </li> <li> <p>Couple this with <code>ignore &lt;breakpoint number&gt; 99999999</code> and after completion/crash use <code>info break</code> to find number of times breakpoint was hit</p> </li> <li> <p>To avoid arbitrary big number add <code>continue</code> to <code>commands &lt;breakpoint number&gt;</code></p> </li> <li> <p><code>cond &lt;breakpoint number&gt; &lt;condition&gt;</code> to make breakpoint conditional</p> </li> <li> <p><code>break foo if bar &gt; 10</code>: create new conditional break point</p> </li> <li> <p><code>break foo thread 3</code>: stop at foo only in thread 3</p> </li> <li> <p><code>watch foo</code>: stop when foo is modified</p> </li> <li> <p>Can be conditions etc. like above</p> </li> <li> <p><code>watch -l</code> evaluates once and then watches the resultant memory location, NOT the reevaluation of the expression</p> </li> <li> <p><code>rwatch</code> is NOT regex watchpoint, but weatch point for reads to things</p> </li> <li> <p><code>awatch</code> is access watchpoint (read or write, but value might not change for example)</p> </li> <li> <p>Backtrace (<code>bt</code>) is useful, but doesn't go back in time</p> </li> <li> <p><code>record</code></p> </li> <li> <p><code>reverse-stepi</code></p> </li> <li> <p><code>reverse-continue</code> (e.g. to a watch point)</p> </li> <li> <p>N.B hardware watchpoints don't work with stack pointer (<code>set can-use-hw-watchpionts 0</code> to force software watch point)</p> <ul> <li> <p>Hardware watch points uses special registers (use too many and you will get an unexplained crash (normally 4))</p> </li> <li> <p>Software watch point evaluates after every step. This incurs a heavy context switching performance penalty</p> </li> <li> <p>Can alleviate this by making sure it is run locally etc. if on a remote machine</p> </li> <li><code>whatis</code> tells you type information</li> </ul> </li> <li> <p>Catchpoints also exist!</p> </li> <li> <p><code>catch catch</code> to stop when C++ exceptions are caught</p> </li> <li> <p><code>catch syscall nanosleep</code> to stop at nanosleep system call</p> </li> <li> <p><code>catch syscall 100</code> to stop at system call number 100</p> </li> <li> <p>You can <code>call</code> functions too e.g. <code>call foo()</code></p> </li> <li> <p>Be aware that this is what happens if you do <code>print foo()</code> too</p> </li> <li> <p><code>dprintf foo.c:10, \"bar is %d\\n\", bar</code> allows you to dynamically add prints without recompiling! At least do this if you have to do printf debugging!</p> </li> <li> <p><code>set dprintf-style gdb|call|agent</code></p> </li> <li> <p><code>set dprintf-function fprintf</code></p> </li> <li> <p><code>set dprintf-channel mylog</code></p> </li> <li> <p><code>skip</code> functions/libraries that your don't care about or trust</p> </li> <li> <p>e.g. <code>skip -rfu ^std::.*</code> will skip stepping into all code in the std namespace</p> </li> <li> <p>This can get a little unintutive if you use things such as callbacks or step out of a function into skipped code etc.</p> </li> <li> <p><code>compile code</code> - compile code typed at console and run it</p> </li> <li> <p><code>compile file</code> compile source code from a file and run it</p> </li> <li> <p><code>compile print</code> use compiler to evaluate an expression, print result</p> </li> <li> <p>All can inject into the program and is very powerful. You can combine this with gdb scripting (<code>cat &lt;flie.gdb&gt; &amp;&amp; cat &gt; gdb ...</code>)</p> </li> <li> <p>You can run commands on gdb startup by using a dotfile: <code>~/.gdbinit</code></p> </li> <li> <p>Compile with <code>-g 3</code> or later etc. to get better debug info (to stop \"value optimised out\" etc.)</p> </li> </ul>"},{"location":"programming/gdb/#docker-compatibility","title":"Docker compatibility","text":"<p>To be able to use <code>gdb</code> in a docker container, you need to run the container with additional arguments.</p> <pre><code>docker run --cap-add=SYS_PTRACE --security-opt seccomp=unconfined ...\n</code></pre> <p>If you are using docker-compose, this can be specified like so:</p> <pre><code>security_opt:\n    - seccomp:unconfined\ncap_add:\n    - SYS_PTRACE\n</code></pre>"},{"location":"windows/command-line-access/","title":"Accessing the Command Line (Root Admin)","text":"<ol> <li><code>shift</code> + restart or use a Windows boot USB</li> <li>Troubleshoot</li> <li>Advanced Options</li> <li>Command Prompt</li> </ol>"},{"location":"windows/diskpart/","title":"Using diskpart","text":"<p>Used for managing partitions, assigning volume letters, etc.</p> <p>Access on the command line:</p> <pre><code>diskpart\n</code></pre> <ul> <li><code>list &lt;disk|volume|partition&gt;</code></li> <li><code>select &lt;disk|volume&gt; &lt;num&gt;</code></li> <li><code>clean</code>: removes all partitions (and data!)</li> <li><code>&lt;assign|remove&gt; letter=&lt;letter&gt;</code> (with volume selected)</li> </ul>"},{"location":"windows/enable-disable-administrator/","title":"Enable/Disable Administrator Account","text":"<p>This can be achieved with the following command:</p> <pre><code>net user Administrator /active:&lt;yes|no&gt;\n</code></pre>"},{"location":"windows/fail-to-boot/","title":"Recovering a Computer that Fails to Boot","text":"<pre><code>bootrec /fixmbr\nbootrec /fixboot\nbootrec /scanos\nbootrec /rebuildbcd\n</code></pre> <p>Restart to check if fixed</p> <p>Still no fix?</p> <pre><code>C:\ncd boot\nattrib bcd -s -h -r\nren bcd bcd.old\nbootrec /rebuildbcd\n</code></pre> <p>This can be reverted with <code>bcdedit /import C:\\boot\\bcd.old</code></p> <p>Restart to check if fixed</p> <p>Still no fix?</p> <pre><code>diskpart\ndiskpart&gt; list disk\ndiskpart&gt; select disk &lt;num&gt; # disk with os installed\ndiskpart&gt; list volume\ndiskpart&gt; select volume &lt;num&gt; # approx 260MB, FAT32 -&gt; looking for EFI partition\ndiskpart&gt; assign letter=b\n\ncd /d b:\\EFI\\Microsoft\\Boot\\\nbootrec /fixboot\nren BCD BCD.old\nbcdboot C:\\Windows /l en-gb /s b: /f ALL\n</code></pre> <p>Fingers crossed and reboot one last time :)</p>"},{"location":"windows/mouse-scroll-direction/","title":"Change mouse scroll direction","text":"<p>In Windows, mouse scroll direction is not an easily accessible option in the normal settings menu (although it is for trackpads!). In order to change the mouse direction, you will need to locate the device in device manager, and check the details section for the hardware ID. Once this is obtained, use the regestry editor to locate the following registry folder:</p> <pre><code>HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Enum\\HID\n</code></pre> <p>Within this folder, you should find a subfolder that matches the hardware ID obtained earlier.  Under \"Device Parameters\", locate <code>FlipFlopWheel</code> and toggle this from <code>0</code> to <code>1</code> as desired to reverse the current direction. For horizontal scroll direction, locate instead <code>FlipFlopHScroll</code> and toggle this value. A restart is needed for this change to take affect.</p>"},{"location":"windows/password-management/","title":"Password Management","text":""},{"location":"windows/password-management/#change-password","title":"Change Password","text":"<p>This can be achieved with the following:</p> <pre><code>net user &lt;username&gt; &lt;new_password&gt;\n</code></pre>"},{"location":"windows/password-management/#enabledisable-password","title":"Enable/Disable Password","text":"<p>This can be achieved with the following:</p> <pre><code>net user &lt;username&gt; /passwordreq:&lt;yes|no&gt;\n</code></pre>"},{"location":"windows/product-key/","title":"Get Windows Product Key","text":"<p>For activation. Useful if computer becomes deactivated after upgrade as it finds the original key.</p> <pre><code>wmic os get \"serialnumber\" # to get serial number if needed\nwmic path softwarelicensingservice get OA3xOriginalProductKey\n</code></pre>"},{"location":"windows/stubborn-files/","title":"Taking ownership of stubborn files","text":"<pre><code>takeown /f &lt;file&gt;\n</code></pre>"}]}