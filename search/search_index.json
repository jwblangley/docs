{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Welcome to my documentation! This is a place where I collate time-saving answers to those infrequent, yet annoying, tasks. Check out the sections with the tabs above! Once you have a tab, use the navigation menu to browse different topics!","title":"Home"},{"location":"#home","text":"Welcome to my documentation! This is a place where I collate time-saving answers to those infrequent, yet annoying, tasks. Check out the sections with the tabs above! Once you have a tab, use the navigation menu to browse different topics!","title":"Home"},{"location":"dual-boot/ubuntu-windows-setup/","text":"Custom Linux (Ubuntu) Install - Method for Setting Up Dual Boot Usually best to install Windows first over the whole disk for a dual boot setup. Continue wizard until \"Installation type\" Select \"Something else\" (For dual boot) Shrink Windows partition to make free space. Recovery partition can be left untouched. Create the following partitions Swap partition Size: >= RAM (for hibernation) Type: Primary (can be logical if \"unstable\" issue occurs) Location: Beginning of space Use as: swap area Root filesystem - used for kernel, boot files, system files, (most) installed programs, libraries, etc. Size: >20GB, I recommend 50GB Type: Logical Location: Beginning of space Use as: ext4 fs Mount point: / Home directory - used for user files. (For dual boot systems I recommend having a common data partition so this becomes less needed) Size: Up to you. Recommended >10GB Type: Logical Location: Beginning of space Use as: ext4 fs Mount point: /home","title":"Custom Linux (Ubuntu) Install - Method for Setting Up Dual Boot"},{"location":"dual-boot/ubuntu-windows-setup/#custom-linux-ubuntu-install-method-for-setting-up-dual-boot","text":"Usually best to install Windows first over the whole disk for a dual boot setup. Continue wizard until \"Installation type\" Select \"Something else\" (For dual boot) Shrink Windows partition to make free space. Recovery partition can be left untouched. Create the following partitions Swap partition Size: >= RAM (for hibernation) Type: Primary (can be logical if \"unstable\" issue occurs) Location: Beginning of space Use as: swap area Root filesystem - used for kernel, boot files, system files, (most) installed programs, libraries, etc. Size: >20GB, I recommend 50GB Type: Logical Location: Beginning of space Use as: ext4 fs Mount point: / Home directory - used for user files. (For dual boot systems I recommend having a common data partition so this becomes less needed) Size: Up to you. Recommended >10GB Type: Logical Location: Beginning of space Use as: ext4 fs Mount point: /home","title":"Custom Linux (Ubuntu) Install - Method for Setting Up Dual Boot"},{"location":"dual-boot/windows-without-grub-menu/","text":"Windows Booting Without GRUB Boot Menu even appearing This can sometimes happen after a Windows update; the bootloader default has been set to Windows rather than GRUB . To fix: set bootloader back to GRUB 1. Open cmd (Administrator) 2. bcdedit /set {bootmgr} path \\EFI\\ubuntu\\grubx64.efi","title":"Windows Booting Without GRUB Boot Menu even appearing"},{"location":"dual-boot/windows-without-grub-menu/#windows-booting-without-grub-boot-menu-even-appearing","text":"This can sometimes happen after a Windows update; the bootloader default has been set to Windows rather than GRUB . To fix: set bootloader back to GRUB 1. Open cmd (Administrator) 2. bcdedit /set {bootmgr} path \\EFI\\ubuntu\\grubx64.efi","title":"Windows Booting Without GRUB Boot Menu even appearing"},{"location":"git/alias/","text":"Git Alias You can create custom git commands with git alias git config [--global] alias.co \"checkout\"","title":"Git Alias"},{"location":"git/alias/#git-alias","text":"You can create custom git commands with git alias git config [--global] alias.co \"checkout\"","title":"Git Alias"},{"location":"git/checkout-deprecation/","text":"The splitting/deprecation of git checkout The git checkout command has two distinct uses. One is to switch and/or create branches and the other is to restore files to a previous index. These two functions have been separated out to avoid confusion. Switch To switch branches, you should now use the following: git switch <branch> adding -c to create a new branch. Restore To restore files from a previous index, you should now use the following: git restore -s <ref> <path> This allows a new feature: restoring with patches using the -p command, similar to it's usage in git add .","title":"The splitting/deprecation of git checkout"},{"location":"git/checkout-deprecation/#the-splittingdeprecation-of-git-checkout","text":"The git checkout command has two distinct uses. One is to switch and/or create branches and the other is to restore files to a previous index. These two functions have been separated out to avoid confusion.","title":"The splitting/deprecation of git checkout"},{"location":"git/checkout-deprecation/#switch","text":"To switch branches, you should now use the following: git switch <branch> adding -c to create a new branch.","title":"Switch"},{"location":"git/checkout-deprecation/#restore","text":"To restore files from a previous index, you should now use the following: git restore -s <ref> <path> This allows a new feature: restoring with patches using the -p command, similar to it's usage in git add .","title":"Restore"},{"location":"git/diff/","text":"Diff git diff is a very powerful feature. One notable use of git diff is that it provides more options than regular diff . For example, if there is one small change within one long line, regular diff cannot highlight this for you. git diff , on the other hand, can with the --word-diff flag. Furthermore, git diff can be used outside a git repository using the --no-index flag. This allows is to function as a powerful diff replacement. git diff can also be used in patching .","title":"Diff"},{"location":"git/diff/#diff","text":"git diff is a very powerful feature. One notable use of git diff is that it provides more options than regular diff . For example, if there is one small change within one long line, regular diff cannot highlight this for you. git diff , on the other hand, can with the --word-diff flag. Furthermore, git diff can be used outside a git repository using the --no-index flag. This allows is to function as a powerful diff replacement. git diff can also be used in patching .","title":"Diff"},{"location":"git/dotfile/","text":"Git Dotfile Global git config is stored in $HOME/.gitconfig .","title":"Git Dotfile"},{"location":"git/dotfile/#git-dotfile","text":"Global git config is stored in $HOME/.gitconfig .","title":"Git Dotfile"},{"location":"git/logdog/","text":"Pretty Print Git History Graph This can be achieved with the following command: git log --decorate --oneline --graph This is sometimes referred to as \"git logdog\" and is therefore often aliased as such .","title":"Pretty Print Git History Graph"},{"location":"git/logdog/#pretty-print-git-history-graph","text":"This can be achieved with the following command: git log --decorate --oneline --graph This is sometimes referred to as \"git logdog\" and is therefore often aliased as such .","title":"Pretty Print Git History Graph"},{"location":"git/patch/","text":"Patch Interactive Patch Staging If you have modified a file in multiple places but want to only commit some of your changes git add has a patch option that allows you to interactively choose which parts of the file to stage. git add [<files>] -p Creating and Applying Patches Similar to unix's patch git can be used to make patches The benefit when working in a git repository is that filenames/paths are registered in git history and do not need to be specified To create a diff git diff [<files>] > mypatch.patch To apply a diff git apply mypatch.patch To revert a diff git apply -R mypatch.patch","title":"Patch"},{"location":"git/patch/#patch","text":"","title":"Patch"},{"location":"git/patch/#interactive-patch-staging","text":"If you have modified a file in multiple places but want to only commit some of your changes git add has a patch option that allows you to interactively choose which parts of the file to stage. git add [<files>] -p","title":"Interactive Patch Staging"},{"location":"git/patch/#creating-and-applying-patches","text":"Similar to unix's patch git can be used to make patches The benefit when working in a git repository is that filenames/paths are registered in git history and do not need to be specified To create a diff git diff [<files>] > mypatch.patch To apply a diff git apply mypatch.patch To revert a diff git apply -R mypatch.patch","title":"Creating and Applying Patches"},{"location":"git/pre-commit/","text":"Pre-commit The pre-commit script found in the local git repository ( .git/hooks/pre-commit) can be any executable and will run before a git commit . A useful use case is to check the formatting of code. N.B it is not best practice to modify files in the pre-commit as tempting as it might be, since you may not always want the files to change and this can be frustrating. It is better practice to abort the commit (non-zero return from pre-commit ) and warn why. If, after being warned, you want to commit anyway, pass --no-verify to git commit . Example An example pre-commit script might be the following: #!/bin/bash # Exit on any fail and prevent commit set -e for file in $(git diff --cached --name-only --diff-filter=d | grep \"\\.py$\") do black --check $file done","title":"Pre-commit"},{"location":"git/pre-commit/#pre-commit","text":"The pre-commit script found in the local git repository ( .git/hooks/pre-commit) can be any executable and will run before a git commit . A useful use case is to check the formatting of code. N.B it is not best practice to modify files in the pre-commit as tempting as it might be, since you may not always want the files to change and this can be frustrating. It is better practice to abort the commit (non-zero return from pre-commit ) and warn why. If, after being warned, you want to commit anyway, pass --no-verify to git commit .","title":"Pre-commit"},{"location":"git/pre-commit/#example","text":"An example pre-commit script might be the following: #!/bin/bash # Exit on any fail and prevent commit set -e for file in $(git diff --cached --name-only --diff-filter=d | grep \"\\.py$\") do black --check $file done","title":"Example"},{"location":"git/rebase/","text":"Rebase Rebasing is a method of overwriting history by moving commits fromone place to another. Typical usage may look like git rebase main which will move the commits from the current branch onto the main branch. Onto A typical scenario is creating a branch from an existing non-default branch to continue working (whilst the base branch is in review). Once the base branch has been merged into the default branch, we want to move the new commits to a new branch off the default branch. This is achieved using the following. git rebase --onto <default_branch> <beginning_of_your_work_exclusive> <end_of_your_work_inclusive> Interactive For anything more complicated, I recommend using git rebase <new_base> -i Which can allow you to squash commits etc. Fixups To fix a previous commit and automatically rebase, you can do the following: git commit --fixup <ref> GIT_SEQUENCE_EDITOR=: git rebase -i --autosquash <ref>~1 rerere To Reuse a previous Recorded conflict Resolution automatically, enable git rerere . git config --global rerere.enabled true If you do need to resolve a conflict differently, you can use the following after the fact. git checkout --conflict=merge <path>","title":"Rebase"},{"location":"git/rebase/#rebase","text":"Rebasing is a method of overwriting history by moving commits fromone place to another. Typical usage may look like git rebase main which will move the commits from the current branch onto the main branch.","title":"Rebase"},{"location":"git/rebase/#onto","text":"A typical scenario is creating a branch from an existing non-default branch to continue working (whilst the base branch is in review). Once the base branch has been merged into the default branch, we want to move the new commits to a new branch off the default branch. This is achieved using the following. git rebase --onto <default_branch> <beginning_of_your_work_exclusive> <end_of_your_work_inclusive>","title":"Onto"},{"location":"git/rebase/#interactive","text":"For anything more complicated, I recommend using git rebase <new_base> -i Which can allow you to squash commits etc.","title":"Interactive"},{"location":"git/rebase/#fixups","text":"To fix a previous commit and automatically rebase, you can do the following: git commit --fixup <ref> GIT_SEQUENCE_EDITOR=: git rebase -i --autosquash <ref>~1","title":"Fixups"},{"location":"git/rebase/#rerere","text":"To Reuse a previous Recorded conflict Resolution automatically, enable git rerere . git config --global rerere.enabled true If you do need to resolve a conflict differently, you can use the following after the fact. git checkout --conflict=merge <path>","title":"rerere"},{"location":"git/root/","text":"Report Root Directory of Current Git Repo This can be achieved with the following command: git rev-parse --show-toplevel","title":"Report Root Directory of Current Git Repo"},{"location":"git/root/#report-root-directory-of-current-git-repo","text":"This can be achieved with the following command: git rev-parse --show-toplevel","title":"Report Root Directory of Current Git Repo"},{"location":"git/submodules/","text":"Submodules Submodules are a powerful git feature that allows other git repositories to be used with a super-repository whilst maintaining individual version control. These commands will help to quickly start using git submodules git submodule add <remote> : add a new git submodule git submodule update : checkout commited index of submodules --init : also initialise git submodules. This is required after a new git clone --remote : checkout the most recent commit for the submodules rather than the one in the index Simply cd into the respective submodule directory to access git commands respective to that submodule.","title":"Submodules"},{"location":"git/submodules/#submodules","text":"Submodules are a powerful git feature that allows other git repositories to be used with a super-repository whilst maintaining individual version control. These commands will help to quickly start using git submodules git submodule add <remote> : add a new git submodule git submodule update : checkout commited index of submodules --init : also initialise git submodules. This is required after a new git clone --remote : checkout the most recent commit for the submodules rather than the one in the index Simply cd into the respective submodule directory to access git commands respective to that submodule.","title":"Submodules"},{"location":"programming/gdb/","text":"GDB Debugging tui enable enables the text-user-interface mode where you can see in with a split-window the current code location focus cmd to make arrows keys work normally in tui mode ctrl+l if tui mode messes up tab autocomplete to find options breakpoints tbreak : temporary break rbreak : match regular expression to break point locations and add for all of them crtl+x+2 : second window; cycle through ignore <breakpoint number> <occurunces> to skip over a breakpoint a certain number of times -> very useful if determinsitic program fails after a certain number of times Couple this with ignore <breakpoint number> 99999999 and after completion/crash use info break to find number of times breakpoint was hit To avoid arbitrary big number add continue to commands <breakpoint number> cond <breakpoint number> <condition> to make breakpoint conditional break foo if bar > 10 : create new conditional break point break foo thread 3 : stop at foo only in thread 3 watch foo : stop when foo is modified Can be conditions etc. like above watch -l evaluates once and then watches the resultant memory location, NOT the reevaluation of the expression rwatch is NOT regex watchpoint, but weatch point for reads to things awatch is access watchpoint (read or write, but value might not change for example) Backtrace ( bt ) is useful, but doesn't go back in time record reverse-stepi reverse-continue (e.g. to a watch point) N.B hardware watchpoints don't work with stack pointer ( set can-use-hw-watchpionts 0 to force software watch point) Hardware watch points uses special registers (use too many and you will get an unexplained crash (normally 4)) Software watch point evaluates after every step. This incurs a heavy context switching performance penalty Can alleviate this by making sure it is run locally etc. if on a remote machine whatis tells you type information Catchpoints also exist! catch catch to stop when C++ exceptions are caught catch syscall nanosleep to stop at nanosleep system call catch syscall 100 to stop at system call number 100 You can call functions too e.g. call foo() Be aware that this is what happens if you do print foo() too dprintf foo.c:10, \"bar is %d\\n\", bar allows you to dynamically add prints without recompiling! At least do this if you have to do printf debugging! set dprintf-style gdb|call|agent set dprintf-function fprintf set dprintf-channel mylog skip functions/libraries that your don't care about or trust e.g. skip -rfu ^std::.* will skip stepping into all code in the std namespace This can get a little unintutive if you use things such as callbacks or step out of a function into skipped code etc. compile code - compile code typed at console and run it compile file compile source code from a file and run it compile print use compiler to evaluate an expression, print result All can inject into the program and is very powerful. You can combine this with gdb scripting ( cat <flie.gdb> && cat > gdb ... ) You can run commands on gdb startup by using a dotfile: ~/.gdbinit Compile with -g 3 or later etc. to get better debug info (to stop \"value optimised out\" etc.) Docker compatibility To be able to use gdb in a docker container, you need to run the container with additional arguments. docker run --cap-add=SYS_PTRACE --security-opt seccomp=unconfined ... If you are using docker-compose, this can be specified like so: security_opt: - seccomp:unconfined cap_add: - SYS_PTRACE","title":"GDB Debugging"},{"location":"programming/gdb/#gdb-debugging","text":"tui enable enables the text-user-interface mode where you can see in with a split-window the current code location focus cmd to make arrows keys work normally in tui mode ctrl+l if tui mode messes up tab autocomplete to find options breakpoints tbreak : temporary break rbreak : match regular expression to break point locations and add for all of them crtl+x+2 : second window; cycle through ignore <breakpoint number> <occurunces> to skip over a breakpoint a certain number of times -> very useful if determinsitic program fails after a certain number of times Couple this with ignore <breakpoint number> 99999999 and after completion/crash use info break to find number of times breakpoint was hit To avoid arbitrary big number add continue to commands <breakpoint number> cond <breakpoint number> <condition> to make breakpoint conditional break foo if bar > 10 : create new conditional break point break foo thread 3 : stop at foo only in thread 3 watch foo : stop when foo is modified Can be conditions etc. like above watch -l evaluates once and then watches the resultant memory location, NOT the reevaluation of the expression rwatch is NOT regex watchpoint, but weatch point for reads to things awatch is access watchpoint (read or write, but value might not change for example) Backtrace ( bt ) is useful, but doesn't go back in time record reverse-stepi reverse-continue (e.g. to a watch point) N.B hardware watchpoints don't work with stack pointer ( set can-use-hw-watchpionts 0 to force software watch point) Hardware watch points uses special registers (use too many and you will get an unexplained crash (normally 4)) Software watch point evaluates after every step. This incurs a heavy context switching performance penalty Can alleviate this by making sure it is run locally etc. if on a remote machine whatis tells you type information Catchpoints also exist! catch catch to stop when C++ exceptions are caught catch syscall nanosleep to stop at nanosleep system call catch syscall 100 to stop at system call number 100 You can call functions too e.g. call foo() Be aware that this is what happens if you do print foo() too dprintf foo.c:10, \"bar is %d\\n\", bar allows you to dynamically add prints without recompiling! At least do this if you have to do printf debugging! set dprintf-style gdb|call|agent set dprintf-function fprintf set dprintf-channel mylog skip functions/libraries that your don't care about or trust e.g. skip -rfu ^std::.* will skip stepping into all code in the std namespace This can get a little unintutive if you use things such as callbacks or step out of a function into skipped code etc. compile code - compile code typed at console and run it compile file compile source code from a file and run it compile print use compiler to evaluate an expression, print result All can inject into the program and is very powerful. You can combine this with gdb scripting ( cat <flie.gdb> && cat > gdb ... ) You can run commands on gdb startup by using a dotfile: ~/.gdbinit Compile with -g 3 or later etc. to get better debug info (to stop \"value optimised out\" etc.)","title":"GDB Debugging"},{"location":"programming/gdb/#docker-compatibility","text":"To be able to use gdb in a docker container, you need to run the container with additional arguments. docker run --cap-add=SYS_PTRACE --security-opt seccomp=unconfined ... If you are using docker-compose, this can be specified like so: security_opt: - seccomp:unconfined cap_add: - SYS_PTRACE","title":"Docker compatibility"},{"location":"unix/background-processes/","text":"Handling Background Processes See this code snippet on how to handle background processes within a script! #!/usr/bin/env bash echo \"Starting a\" ./a.sh | sed 's/^/A: /'& echo \"Starting b\" ./b.sh | sed 's/^/B: /'& # Forward signals to child processes trap 'trap \"\" SIGTERM; kill 0; wait' SIGINT SIGTERM # Wait for child processes to finish wait","title":"Handling Background Processes"},{"location":"unix/background-processes/#handling-background-processes","text":"See this code snippet on how to handle background processes within a script! #!/usr/bin/env bash echo \"Starting a\" ./a.sh | sed 's/^/A: /'& echo \"Starting b\" ./b.sh | sed 's/^/B: /'& # Forward signals to child processes trap 'trap \"\" SIGTERM; kill 0; wait' SIGINT SIGTERM # Wait for child processes to finish wait","title":"Handling Background Processes"},{"location":"unix/compression/","text":"Compression gzip The gzip command can be used to compress single files. Add the -# replacing # with a number 1-9, for setting the compression level. pigz By default, gzip does not use all cores. This can be ammended by using the pigz command instead. pigz is fully compatible with gzip tar gzip can only compress a single file. tar (or zip - difference being inter-file compression in tar ) creates a single archive file from multiple. Combining tar and gzip is the standard way of making compressed archives. -c : Creates archive (recursive by default) -x : Extracts the archive -f : Creates archive with given filename (use - for stdout) -v : Displays verbose information -z : Compresses the tar file using gzip Examples Create a compressed archive tar cfzv archive.tar file1 file2 file3 Decompress an archive tar xfv archive.tar Create a compressed archive using all CPU cores and the best compression level tar cf - paths-to-archive | pigz -9 > archive.tar.gz","title":"Compression"},{"location":"unix/compression/#compression","text":"","title":"Compression"},{"location":"unix/compression/#gzip","text":"The gzip command can be used to compress single files. Add the -# replacing # with a number 1-9, for setting the compression level.","title":"gzip"},{"location":"unix/compression/#pigz","text":"By default, gzip does not use all cores. This can be ammended by using the pigz command instead. pigz is fully compatible with gzip","title":"pigz"},{"location":"unix/compression/#tar","text":"gzip can only compress a single file. tar (or zip - difference being inter-file compression in tar ) creates a single archive file from multiple. Combining tar and gzip is the standard way of making compressed archives. -c : Creates archive (recursive by default) -x : Extracts the archive -f : Creates archive with given filename (use - for stdout) -v : Displays verbose information -z : Compresses the tar file using gzip","title":"tar"},{"location":"unix/compression/#examples","text":"","title":"Examples"},{"location":"unix/compression/#create-a-compressed-archive","text":"tar cfzv archive.tar file1 file2 file3","title":"Create a compressed archive"},{"location":"unix/compression/#decompress-an-archive","text":"tar xfv archive.tar","title":"Decompress an archive"},{"location":"unix/compression/#create-a-compressed-archive-using-all-cpu-cores-and-the-best-compression-level","text":"tar cf - paths-to-archive | pigz -9 > archive.tar.gz","title":"Create a compressed archive using all CPU cores and the best compression level"},{"location":"unix/ffmpeg/","text":"ffmpeg ffmpeg is a fantastic tool that allows complete conversion of video formats Basic syntax ffmpeg -i input.avi output.mp4` ffmpeg -i img%03d.png out.mp4 Gotchas Not all h264 formats are available on multiple platforms. The most platform-agnostic format is yuv420p (nothing to do with 420 pixels) bash ffmpeg -i input.mp4 -vf format=yuv420p output.mp4","title":"ffmpeg"},{"location":"unix/ffmpeg/#ffmpeg","text":"ffmpeg is a fantastic tool that allows complete conversion of video formats","title":"ffmpeg"},{"location":"unix/ffmpeg/#basic-syntax","text":"ffmpeg -i input.avi output.mp4` ffmpeg -i img%03d.png out.mp4","title":"Basic syntax"},{"location":"unix/ffmpeg/#gotchas","text":"Not all h264 formats are available on multiple platforms. The most platform-agnostic format is yuv420p (nothing to do with 420 pixels) bash ffmpeg -i input.mp4 -vf format=yuv420p output.mp4","title":"Gotchas"},{"location":"unix/gpg/","text":"Encryption Encryption can be achieved either using gpg and/or openssl . Symmetric Encryption A simple symmetric encryption can be achieved with the following: gpg -c <file> which will prompt for a passphrase and produce an encrypted file with an appended .gpg suffix. To decrypt the encrypted file use the following: gpg <encrypted_file> Encryption Algorithm gpg allows a number of algorithms. To view these algorithms run: gpg --version For symmetric encryption, look for algorithms listed under Cypher: . Using one of these algorithms can be achieved as follows. gpg --cipher-algo <ALGO> <file> No change is required to the decrypt command. Asymmetric Encryption You can see a list of keys with gpg --list-keys . --list-secret-keys and --list-public-keys are also available. Generate a key pair bash gpg --gen-key Export your public key bash gpg --export --armor <name> > <name>.pub (Optional) Make a backup of your private key. Only ever store this backup in offline media. bash gpg --export-secret-keys --armor <name> > <name>.priv Import the other's public key bash gpg --import key.pub (Optional) Trust the key bash gpg --edit-key <name> Enter trust then the level you wish to trust it to Encrypt a file bash gpg --encrypt --recipient <recipient> <file> Decrypt a received file bash gpg --decrypt <file>.gpg --output <file>","title":"Encryption"},{"location":"unix/gpg/#encryption","text":"Encryption can be achieved either using gpg and/or openssl .","title":"Encryption"},{"location":"unix/gpg/#symmetric-encryption","text":"A simple symmetric encryption can be achieved with the following: gpg -c <file> which will prompt for a passphrase and produce an encrypted file with an appended .gpg suffix. To decrypt the encrypted file use the following: gpg <encrypted_file>","title":"Symmetric Encryption"},{"location":"unix/gpg/#encryption-algorithm","text":"gpg allows a number of algorithms. To view these algorithms run: gpg --version For symmetric encryption, look for algorithms listed under Cypher: . Using one of these algorithms can be achieved as follows. gpg --cipher-algo <ALGO> <file> No change is required to the decrypt command.","title":"Encryption Algorithm"},{"location":"unix/gpg/#asymmetric-encryption","text":"You can see a list of keys with gpg --list-keys . --list-secret-keys and --list-public-keys are also available. Generate a key pair bash gpg --gen-key Export your public key bash gpg --export --armor <name> > <name>.pub (Optional) Make a backup of your private key. Only ever store this backup in offline media. bash gpg --export-secret-keys --armor <name> > <name>.priv Import the other's public key bash gpg --import key.pub (Optional) Trust the key bash gpg --edit-key <name> Enter trust then the level you wish to trust it to Encrypt a file bash gpg --encrypt --recipient <recipient> <file> Decrypt a received file bash gpg --decrypt <file>.gpg --output <file>","title":"Asymmetric Encryption"},{"location":"unix/grep/","text":"grep grep is a well-known, useful command line utility to filter stdin. Here are some lesser-known features. Regular expressions Invoking grep with the -E flag allows you to use extended regular expressions. Matching patterns that come from a file You might be in a use case where your patterns are defined in a file and you want to use this to grep your input. This template can be (modified and) used to achieve this. grep $(sed \"s/^/-e /;s/$/ /\" patterns.txt | tr -d \"\\n\")","title":"grep"},{"location":"unix/grep/#grep","text":"grep is a well-known, useful command line utility to filter stdin. Here are some lesser-known features.","title":"grep"},{"location":"unix/grep/#regular-expressions","text":"Invoking grep with the -E flag allows you to use extended regular expressions.","title":"Regular expressions"},{"location":"unix/grep/#matching-patterns-that-come-from-a-file","text":"You might be in a use case where your patterns are defined in a file and you want to use this to grep your input. This template can be (modified and) used to achieve this. grep $(sed \"s/^/-e /;s/$/ /\" patterns.txt | tr -d \"\\n\")","title":"Matching patterns that come from a file"},{"location":"unix/mounting-drive-partitions/","text":"Mounting Drives/Partitions Use gparted or gnome-disks to find (with GUI) partition name . Or use fdisk -l to do this via command line (harder to understand). N.B: devices look like /dev/sdx and partitions look like /dev/sdxY . e.g. /dev/sda and /dev/sda1 respectively. bash mount <parition_name> <mount_point> -o uid=$UID -o gid=$GID # ... When finished, don't forget to umount <mount_point> To mount part of a hard drive into the local directory (e.g. so that docker can use it without symlinks), add the following to /etc/fstab # Bind /hdd/server to /home/server/hdd /hdd/server /home/server/hdd none defaults,bind 0 0 Similar to this is what is happening automatically when using gnome-disks","title":"Mounting Drives/Partitions"},{"location":"unix/mounting-drive-partitions/#mounting-drivespartitions","text":"Use gparted or gnome-disks to find (with GUI) partition name . Or use fdisk -l to do this via command line (harder to understand). N.B: devices look like /dev/sdx and partitions look like /dev/sdxY . e.g. /dev/sda and /dev/sda1 respectively. bash mount <parition_name> <mount_point> -o uid=$UID -o gid=$GID # ... When finished, don't forget to umount <mount_point> To mount part of a hard drive into the local directory (e.g. so that docker can use it without symlinks), add the following to /etc/fstab # Bind /hdd/server to /home/server/hdd /hdd/server /home/server/hdd none defaults,bind 0 0 Similar to this is what is happening automatically when using gnome-disks","title":"Mounting Drives/Partitions"},{"location":"unix/networking/","text":"Networking IP rules The iptables command can be used to create IP rules such as dropping, rejecting, masquerading or forwarding packets that meet certain criteria. This is how wireguard is configured. It is important to note, however, that iptables rules only persist whilst the host is up and are lost at reboot. A good alternative is the uncomplicated firewall of ufw , which uses iptables under the hood, but provides a more user-friendly interface and manages persistence of iptables rules. A very important notice is that docker creates it's own iptables rules for it's own networking capabilities. This happens in the layer before ufw and therefore ufw rules configured for endpoints that docker controls will not take affect! iptables can be used for network address translation (or NAT). Whilst this works perfectly for TCP connections that have state, UDP packets are stateless, without additional software (such as a STUN server ), UDP packets cannot successfully be routes through NATs since they require full bidirectional communication before they are considered ESTABLISHED (at which point a NAT entry would suffice). This can be confirmed using conntrack and wireshark. Choice of VPN software There is a long-fought argument between Wireguard and OpenVPN. I have personally had success with both, however since Wireguard makes use of a new network kernel interface (called wg0 ) NAT is as-good-as mandatory. Due to the issues above with UDP and NAT, I prefer to use OpenVPN since it can be configured (without NAT) much more easily.","title":"Networking"},{"location":"unix/networking/#networking","text":"","title":"Networking"},{"location":"unix/networking/#ip-rules","text":"The iptables command can be used to create IP rules such as dropping, rejecting, masquerading or forwarding packets that meet certain criteria. This is how wireguard is configured. It is important to note, however, that iptables rules only persist whilst the host is up and are lost at reboot. A good alternative is the uncomplicated firewall of ufw , which uses iptables under the hood, but provides a more user-friendly interface and manages persistence of iptables rules. A very important notice is that docker creates it's own iptables rules for it's own networking capabilities. This happens in the layer before ufw and therefore ufw rules configured for endpoints that docker controls will not take affect! iptables can be used for network address translation (or NAT). Whilst this works perfectly for TCP connections that have state, UDP packets are stateless, without additional software (such as a STUN server ), UDP packets cannot successfully be routes through NATs since they require full bidirectional communication before they are considered ESTABLISHED (at which point a NAT entry would suffice). This can be confirmed using conntrack and wireshark.","title":"IP rules"},{"location":"unix/networking/#choice-of-vpn-software","text":"There is a long-fought argument between Wireguard and OpenVPN. I have personally had success with both, however since Wireguard makes use of a new network kernel interface (called wg0 ) NAT is as-good-as mandatory. Due to the issues above with UDP and NAT, I prefer to use OpenVPN since it can be configured (without NAT) much more easily.","title":"Choice of VPN software"},{"location":"unix/parallel/","text":"GNU Parallel To execute arbitrary commands in parallel (multi-process), making use of additional CPU cores, across input data, GNU parallel can be used. A basic example is as follows: find . -name '*.html' | parallel gzip --best and more examples can be found here .","title":"GNU Parallel"},{"location":"unix/parallel/#gnu-parallel","text":"To execute arbitrary commands in parallel (multi-process), making use of additional CPU cores, across input data, GNU parallel can be used. A basic example is as follows: find . -name '*.html' | parallel gzip --best and more examples can be found here .","title":"GNU Parallel"},{"location":"unix/patch/","text":"Patch The patch command can usefully apply patches that are created with the diff tool. For example: Generate a patch file diff foo.txt bar.txt > foo2bar.patch Apply the patch file patch foo.txt foo2bar.patch Reverse the patch patch -R foot.txt foo2bar.patch","title":"Patch"},{"location":"unix/patch/#patch","text":"The patch command can usefully apply patches that are created with the diff tool. For example: Generate a patch file diff foo.txt bar.txt > foo2bar.patch Apply the patch file patch foo.txt foo2bar.patch Reverse the patch patch -R foot.txt foo2bar.patch","title":"Patch"},{"location":"unix/ram-disk/","text":"RAMDisk mount -t tmpfs -o rw,size=<size> <name> <mount_point> # ... When finished, don't forget to umount <local_mount_point>","title":"RAMDisk"},{"location":"unix/ram-disk/#ramdisk","text":"mount -t tmpfs -o rw,size=<size> <name> <mount_point> # ... When finished, don't forget to umount <local_mount_point>","title":"RAMDisk"},{"location":"unix/remote-file-access/","text":"Remote File Access sftp Good for simple single file transfers -a flag is really useful to continue transfer if it gets interrupted sshfs Mounts the remote file system Method: bash mkdir <local_mount_point> # (usually /tmp/remote is a good choice) sshfs <user>@<remote>:<remote_mount_point> <local_mount_point> # ... When finished, don't forget to umount <local_mount_point>","title":"Remote File Access"},{"location":"unix/remote-file-access/#remote-file-access","text":"","title":"Remote File Access"},{"location":"unix/remote-file-access/#sftp","text":"Good for simple single file transfers -a flag is really useful to continue transfer if it gets interrupted","title":"sftp"},{"location":"unix/remote-file-access/#sshfs","text":"Mounts the remote file system Method: bash mkdir <local_mount_point> # (usually /tmp/remote is a good choice) sshfs <user>@<remote>:<remote_mount_point> <local_mount_point> # ... When finished, don't forget to umount <local_mount_point>","title":"sshfs"},{"location":"unix/ssh-display/","text":"Graphical Applications Over SSH Pass the -X or -Y flag Need $DISPLAY environment variable. If using sudo , use sudo -E .","title":"Graphical Applications Over SSH"},{"location":"unix/ssh-display/#graphical-applications-over-ssh","text":"Pass the -X or -Y flag Need $DISPLAY environment variable. If using sudo , use sudo -E .","title":"Graphical Applications Over SSH"},{"location":"unix/ssh-vpn/","text":"SSH as a VPN ssh can actually be used to tunnel network traffic also! ssh -N -L <local_port>:<remote>:<remote_port> <user>@<remote> e.g. ssh -N -L 12345:example.com:443 james@abc.com Will set up a tunnel such that example.com:443 (443 is https ) can be accessed at localhost:12345 tunnelling traffic through james@abc.com","title":"SSH as a VPN"},{"location":"unix/ssh-vpn/#ssh-as-a-vpn","text":"ssh can actually be used to tunnel network traffic also! ssh -N -L <local_port>:<remote>:<remote_port> <user>@<remote> e.g. ssh -N -L 12345:example.com:443 james@abc.com Will set up a tunnel such that example.com:443 (443 is https ) can be accessed at localhost:12345 tunnelling traffic through james@abc.com","title":"SSH as a VPN"},{"location":"unix/ssl/","text":"SSL Certificates To generate an SSL certificate and private key pair, use the following command: openssl req -x509 -newkey rsa:4096 -keyout privatekey.key -out public-certificate.crt -sha256 -days 365 Add the -nodes flag to disable DES passphrase encryption -days specifies the time until expiry","title":"SSL Certificates"},{"location":"unix/ssl/#ssl-certificates","text":"To generate an SSL certificate and private key pair, use the following command: openssl req -x509 -newkey rsa:4096 -keyout privatekey.key -out public-certificate.crt -sha256 -days 365 Add the -nodes flag to disable DES passphrase encryption -days specifies the time until expiry","title":"SSL Certificates"},{"location":"unix/xargs/","text":"xargs xargs is a command line utility that formats stdin correctly for another program's arguments and invokes that program For example, by default the command ls outputs over a number of lines, but ls | xargs will push these onto one line (space-separated). This is very useful for substituting a command's results in another command. e.g. ls | xargs rm . N.B: this is a contrived example where rm -r * would be easier. xargs is therefore very useful for scripting, but it also becomes essential if you would otherwise have a massive number of program arguments. For example if you were deleting thousands of files (by name (contrived example)) and were to put them all onto the command line with $() , some would be cut short since there is a maximum argument limit. xargs obeys this and will split the call into multiple calls if necessary to accommodate this. This can be manually achieved with the -n <n> argument which allows only n arguments per call. This also opens up much more scripting potential.","title":"xargs"},{"location":"unix/xargs/#xargs","text":"xargs is a command line utility that formats stdin correctly for another program's arguments and invokes that program For example, by default the command ls outputs over a number of lines, but ls | xargs will push these onto one line (space-separated). This is very useful for substituting a command's results in another command. e.g. ls | xargs rm . N.B: this is a contrived example where rm -r * would be easier. xargs is therefore very useful for scripting, but it also becomes essential if you would otherwise have a massive number of program arguments. For example if you were deleting thousands of files (by name (contrived example)) and were to put them all onto the command line with $() , some would be cut short since there is a maximum argument limit. xargs obeys this and will split the call into multiple calls if necessary to accommodate this. This can be manually achieved with the -n <n> argument which allows only n arguments per call. This also opens up much more scripting potential.","title":"xargs"},{"location":"unix/zsh-ordering/","text":"ZSH script ordering The following scripts run in order for the setup of a zsh shell. .zshenv is always sourced .zprofile runs for login shells .zshrc only runs in interactive shells. Only include setup for interactive shells here .zlogin runs for login shells. Much like .zprofile , but the shell can be considered fully set up .zlogout runs to teardown anything set up in .zlogin Login shells A login shell is either that initially logged into or accessed with ssh . A notable exception therefore are terminal sessions launched through the terminal apps in any UI session. For my usage, I find this to be inconvenient, so I will look for and enable a setting to launch these terminal sessions as login shells.","title":"ZSH script ordering"},{"location":"unix/zsh-ordering/#zsh-script-ordering","text":"The following scripts run in order for the setup of a zsh shell. .zshenv is always sourced .zprofile runs for login shells .zshrc only runs in interactive shells. Only include setup for interactive shells here .zlogin runs for login shells. Much like .zprofile , but the shell can be considered fully set up .zlogout runs to teardown anything set up in .zlogin","title":"ZSH script ordering"},{"location":"unix/zsh-ordering/#login-shells","text":"A login shell is either that initially logged into or accessed with ssh . A notable exception therefore are terminal sessions launched through the terminal apps in any UI session. For my usage, I find this to be inconvenient, so I will look for and enable a setting to launch these terminal sessions as login shells.","title":"Login shells"},{"location":"unix/tmux/shared-session/","text":"Shared tmux Sessions Background tmux will create (directories of) sockets within TMUX_TMPDIR or /tmp if unset. The default socket name is default within this folder This can be changed per call with the -L flag The socket path (e.g. /tmp/tmux-1000/default ) can be changed with the -S flag Sharing To share a session, simply allow other users (via unix user groups) access to the socket In version ( tmux -V ) 3.3 and later an additional step is required. Use tmux server-access -a <user> to add a user (specificying -r or -w for read or write access)","title":"Shared tmux Sessions"},{"location":"unix/tmux/shared-session/#shared-tmux-sessions","text":"","title":"Shared tmux Sessions"},{"location":"unix/tmux/shared-session/#background","text":"tmux will create (directories of) sockets within TMUX_TMPDIR or /tmp if unset. The default socket name is default within this folder This can be changed per call with the -L flag The socket path (e.g. /tmp/tmux-1000/default ) can be changed with the -S flag","title":"Background"},{"location":"unix/tmux/shared-session/#sharing","text":"To share a session, simply allow other users (via unix user groups) access to the socket In version ( tmux -V ) 3.3 and later an additional step is required. Use tmux server-access -a <user> to add a user (specificying -r or -w for read or write access)","title":"Sharing"},{"location":"unix/tmux/start-in-detached/","text":"Starting Services in Detached Sessions tmux new -d [-s <session_name>] \"<starting_command>\"","title":"Starting Services in Detached Sessions"},{"location":"unix/tmux/start-in-detached/#starting-services-in-detached-sessions","text":"tmux new -d [-s <session_name>] \"<starting_command>\"","title":"Starting Services in Detached Sessions"},{"location":"unix/ubuntu/automatic-mount-on-boot/","text":"To Automatically Mount Drives on Boot Use gnome-disks 1. Select partition -> Edit Mount Options 1. Turn off \"user session defaults\" 1. Select \"Mount at system startup\" 1. Fill in other fields as desired (including mount point) 1. reboot","title":"Automatic mount on boot"},{"location":"unix/ubuntu/automatic-mount-on-boot/#to-automatically-mount-drives-on-boot","text":"Use gnome-disks 1. Select partition -> Edit Mount Options 1. Turn off \"user session defaults\" 1. Select \"Mount at system startup\" 1. Fill in other fields as desired (including mount point) 1. reboot","title":"To Automatically Mount Drives on Boot"},{"location":"unix/ubuntu/installing-app-images/","text":"Installing *.AppImage applications Make use of https://github.com/TheAssassin/AppImageLauncher If you want to also be able to run a command from terminal, symlink the installed application (set up in AppImageLauncher) to /usr/local/bin","title":"Installing *.AppImage applications"},{"location":"unix/ubuntu/installing-app-images/#installing-appimage-applications","text":"Make use of https://github.com/TheAssassin/AppImageLauncher If you want to also be able to run a command from terminal, symlink the installed application (set up in AppImageLauncher) to /usr/local/bin","title":"Installing *.AppImage applications"},{"location":"unix/ubuntu/managing-installs/","text":"Managing Installed Programs Find manually installed programs to find those you no longer need bash sudo apt-mark showmanual snap list # for any programs installed by snap Clean list of ppa s after uninstalling ppa s are listed in the sources.list file and as individual files in the sources.list.d/ subfolder in etc/apt","title":"Managing Installed Programs"},{"location":"unix/ubuntu/managing-installs/#managing-installed-programs","text":"Find manually installed programs to find those you no longer need bash sudo apt-mark showmanual snap list # for any programs installed by snap Clean list of ppa s after uninstalling ppa s are listed in the sources.list file and as individual files in the sources.list.d/ subfolder in etc/apt","title":"Managing Installed Programs"},{"location":"unix/ubuntu/mounts-in-dock/","text":"To Turn On/Off Mounts from Appearing in the Dock gsettings set org.gnome.shell.extensions.dash-to-dock show-mounts <true|false>","title":"To Turn On/Off Mounts from Appearing in the Dock"},{"location":"unix/ubuntu/mounts-in-dock/#to-turn-onoff-mounts-from-appearing-in-the-dock","text":"gsettings set org.gnome.shell.extensions.dash-to-dock show-mounts <true|false>","title":"To Turn On/Off Mounts from Appearing in the Dock"},{"location":"unix/ubuntu/prevent-sleep/","text":"Prevent/Allow Ubuntu Sleeping e.g. For an Ubuntu Server sudo systemctl <mask|unmask> sleep.target suspend.target hibernate.target hybrid-sleep.target mask to prevent sleeping, unmask to (re)allow sleeping","title":"Prevent/Allow Ubuntu Sleeping"},{"location":"unix/ubuntu/prevent-sleep/#preventallow-ubuntu-sleeping","text":"e.g. For an Ubuntu Server sudo systemctl <mask|unmask> sleep.target suspend.target hibernate.target hybrid-sleep.target mask to prevent sleeping, unmask to (re)allow sleeping","title":"Prevent/Allow Ubuntu Sleeping"},{"location":"unix/ubuntu/screen-recording/","text":"Screen Recording I like to use Peek for screen recording.","title":"Screen Recording"},{"location":"unix/ubuntu/screen-recording/#screen-recording","text":"I like to use Peek for screen recording.","title":"Screen Recording"},{"location":"unix/ubuntu/terminal-clipboard/","text":"Use of the (Desktop) Clipboard in the Command Line xclip * -o : paste to stdout * Use -sel clip option to use the main clipboard. Defaults to middle-mouse-click temporary clipboard otherwise. * Very useful when combined with pipes e.g. echo \"test\" | xclip -sel clip","title":"Use of the (Desktop) Clipboard in the Command Line"},{"location":"unix/ubuntu/terminal-clipboard/#use-of-the-desktop-clipboard-in-the-command-line","text":"xclip * -o : paste to stdout * Use -sel clip option to use the main clipboard. Defaults to middle-mouse-click temporary clipboard otherwise. * Very useful when combined with pipes e.g. echo \"test\" | xclip -sel clip","title":"Use of the (Desktop) Clipboard in the Command Line"},{"location":"unix/ubuntu/updating-ubuntu/","text":"Updating Ubuntu GUI (recommended) Sotware Updater Terminal sudo apt update sudo apt upgrade sudo do-release-upgrade # -c to check for upgrades After the updates Some ppa s and software might have been removed GUI (recommended) Can be launched with software-properties-gtk (e.g. with ssh -X or -Y) * Remove anything from \"other software\" and \"authentication\" that has been disabled by the upgrade and make a note of which . Terminal Manipulate sources.list to remove any software that was disabled by the upgrade and make a note of which . apt update should now run without any errors or warnings Reinstall those that were removed","title":"Updating Ubuntu"},{"location":"unix/ubuntu/updating-ubuntu/#updating-ubuntu","text":"","title":"Updating Ubuntu"},{"location":"unix/ubuntu/updating-ubuntu/#gui-recommended","text":"Sotware Updater","title":"GUI (recommended)"},{"location":"unix/ubuntu/updating-ubuntu/#terminal","text":"sudo apt update sudo apt upgrade sudo do-release-upgrade # -c to check for upgrades","title":"Terminal"},{"location":"unix/ubuntu/updating-ubuntu/#after-the-updates","text":"Some ppa s and software might have been removed","title":"After the updates"},{"location":"unix/ubuntu/updating-ubuntu/#gui-recommended_1","text":"Can be launched with software-properties-gtk (e.g. with ssh -X or -Y) * Remove anything from \"other software\" and \"authentication\" that has been disabled by the upgrade and make a note of which .","title":"GUI (recommended)"},{"location":"unix/ubuntu/updating-ubuntu/#terminal_1","text":"Manipulate sources.list to remove any software that was disabled by the upgrade and make a note of which . apt update should now run without any errors or warnings Reinstall those that were removed","title":"Terminal"},{"location":"unix/ubuntu/version-management/","text":"Managing Versions of Programs on the Path This is particularly relevant for Java (especially when wanting to work with Oracle Java), so these instructions will be tailored to that. Install version files (for java to /usr/lib/jvm/jdkx.x.x_xxx ) Register with update-alternatives bash sudo update-alternatives --install \"/usr/bin/java\" \"java\" \"/usr/lib/jvm/jdkx.x.x_xxx/bin/java\" 1 Installation to, command name, program file, priority for auto-selection (not relevant as we will use manual selection) Select which version to use bash sudo update-alternatives --config java Then type the chosen installation number N.B for java, it is best to do this process for java and javac","title":"Managing Versions of Programs on the Path"},{"location":"unix/ubuntu/version-management/#managing-versions-of-programs-on-the-path","text":"This is particularly relevant for Java (especially when wanting to work with Oracle Java), so these instructions will be tailored to that. Install version files (for java to /usr/lib/jvm/jdkx.x.x_xxx ) Register with update-alternatives bash sudo update-alternatives --install \"/usr/bin/java\" \"java\" \"/usr/lib/jvm/jdkx.x.x_xxx/bin/java\" 1 Installation to, command name, program file, priority for auto-selection (not relevant as we will use manual selection) Select which version to use bash sudo update-alternatives --config java Then type the chosen installation number N.B for java, it is best to do this process for java and javac","title":"Managing Versions of Programs on the Path"},{"location":"windows/command-line-access/","text":"Accessing the Command Line (Root Admin) shift + restart or use a Windows boot USB Troubleshoot Advanced Options Command Prompt","title":"Accessing the Command Line (Root Admin)"},{"location":"windows/command-line-access/#accessing-the-command-line-root-admin","text":"shift + restart or use a Windows boot USB Troubleshoot Advanced Options Command Prompt","title":"Accessing the Command Line (Root Admin)"},{"location":"windows/diskpart/","text":"Using diskpart Used for managing partitions, assigning volume letters, etc. Access on the command line: diskpart list <disk|volume|partition> select <disk|volume> <num> clean : removes all partitions (and data!) <assign|remove> letter=<letter> (with volume selected)","title":"Using diskpart"},{"location":"windows/diskpart/#using-diskpart","text":"Used for managing partitions, assigning volume letters, etc. Access on the command line: diskpart list <disk|volume|partition> select <disk|volume> <num> clean : removes all partitions (and data!) <assign|remove> letter=<letter> (with volume selected)","title":"Using diskpart"},{"location":"windows/enable-disable-administrator/","text":"Enable/Disable Administrator Account This can be achieved with the following command: net user Administrator /active:<yes|no>","title":"Enable/Disable Administrator Account"},{"location":"windows/enable-disable-administrator/#enabledisable-administrator-account","text":"This can be achieved with the following command: net user Administrator /active:<yes|no>","title":"Enable/Disable Administrator Account"},{"location":"windows/fail-to-boot/","text":"Recovering a Computer that Fails to Boot bootrec /fixmbr bootrec /fixboot bootrec /scanos bootrec /rebuildbcd Restart to check if fixed Still no fix? C: cd boot attrib bcd -s -h -r ren bcd bcd.old bootrec /rebuildbcd This can be reverted with bcdedit /import C:\\boot\\bcd.old Restart to check if fixed Still no fix? diskpart diskpart> list disk diskpart> select disk <num> # disk with os installed diskpart> list volume diskpart> select volume <num> # approx 260MB, FAT32 -> looking for EFI partition diskpart> assign letter=b cd /d b:\\EFI\\Microsoft\\Boot\\ bootrec /fixboot ren BCD BCD.old bcdboot C:\\Windows /l en-gb /s b: /f ALL Fingers crossed and reboot one last time :)","title":"Recovering a Computer that Fails to Boot"},{"location":"windows/fail-to-boot/#recovering-a-computer-that-fails-to-boot","text":"bootrec /fixmbr bootrec /fixboot bootrec /scanos bootrec /rebuildbcd Restart to check if fixed Still no fix? C: cd boot attrib bcd -s -h -r ren bcd bcd.old bootrec /rebuildbcd This can be reverted with bcdedit /import C:\\boot\\bcd.old Restart to check if fixed Still no fix? diskpart diskpart> list disk diskpart> select disk <num> # disk with os installed diskpart> list volume diskpart> select volume <num> # approx 260MB, FAT32 -> looking for EFI partition diskpart> assign letter=b cd /d b:\\EFI\\Microsoft\\Boot\\ bootrec /fixboot ren BCD BCD.old bcdboot C:\\Windows /l en-gb /s b: /f ALL Fingers crossed and reboot one last time :)","title":"Recovering a Computer that Fails to Boot"},{"location":"windows/mouse-scroll-direction/","text":"Change mouse scroll direction In Windows, mouse scroll direction is not an easily accessible option in the normal settings menu (although it is for trackpads!). In order to change the mouse direction, you will need to locate the device in device manager, and check the details section for the hardware ID. Once this is obtained, use the regestry editor to locate the following registry folder: HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Enum\\HID Within this folder, you should find a subfolder that matches the hardware ID obtained earlier. Under \"Device Parameters\", locate FlipFlopWheel and toggle this from 0 to 1 as desired to reverse the current direction. For horizontal scroll direction, locate instead FlipFlopHScroll and toggle this value. A restart is needed for this change to take affect.","title":"Change mouse scroll direction"},{"location":"windows/mouse-scroll-direction/#change-mouse-scroll-direction","text":"In Windows, mouse scroll direction is not an easily accessible option in the normal settings menu (although it is for trackpads!). In order to change the mouse direction, you will need to locate the device in device manager, and check the details section for the hardware ID. Once this is obtained, use the regestry editor to locate the following registry folder: HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Enum\\HID Within this folder, you should find a subfolder that matches the hardware ID obtained earlier. Under \"Device Parameters\", locate FlipFlopWheel and toggle this from 0 to 1 as desired to reverse the current direction. For horizontal scroll direction, locate instead FlipFlopHScroll and toggle this value. A restart is needed for this change to take affect.","title":"Change mouse scroll direction"},{"location":"windows/password-management/","text":"Password Management Change Password This can be achieved with the following: net user <username> <new_password> Enable/Disable Password This can be achieved with the following: net user <username> /passwordreq:<yes|no>","title":"Password Management"},{"location":"windows/password-management/#password-management","text":"","title":"Password Management"},{"location":"windows/password-management/#change-password","text":"This can be achieved with the following: net user <username> <new_password>","title":"Change Password"},{"location":"windows/password-management/#enabledisable-password","text":"This can be achieved with the following: net user <username> /passwordreq:<yes|no>","title":"Enable/Disable Password"},{"location":"windows/product-key/","text":"Get Windows Product Key For activation. Useful if computer becomes deactivated after upgrade as it finds the original key. wmic os get \"serialnumber\" # to get serial number if needed wmic path softwarelicensingservice get OA3xOriginalProductKey","title":"Get Windows Product Key"},{"location":"windows/product-key/#get-windows-product-key","text":"For activation. Useful if computer becomes deactivated after upgrade as it finds the original key. wmic os get \"serialnumber\" # to get serial number if needed wmic path softwarelicensingservice get OA3xOriginalProductKey","title":"Get Windows Product Key"},{"location":"windows/stubborn-files/","text":"Taking ownership of stubborn files takeown /f <file>","title":"Taking ownership of stubborn files"},{"location":"windows/stubborn-files/#taking-ownership-of-stubborn-files","text":"takeown /f <file>","title":"Taking ownership of stubborn files"}]}